---
title: Services Configuration
date: 2015-05-25 00:00:00 Z
categories:
- docker
tags:
- docker
- jet
- configuration
- services
layout: page
weight: 56
---

* include a table of contents
{:toc}

## Modular environments instead of one size fits all

One of the issues that we set out to solve with our new infrastructure was providing a more modular and composable build environment for our customers. Why should the tools that are only necessary during your deployment be installed in the environment that your tests run in? Why can’t we build small containers, a plugin infrastructure if you want, and plug those specialized containers into the parts of the build where we need them?

With Docker at the basis of our new infrastructure, this has now become possible. You can pull in any container you like to compose your build environment. These can be official Docker containers, [provided by different companies like Codeship](https://hub.docker.com/u/codeship), or even your own pulled from a private registry. You can connect those containers to build your environment that can go from simple database support for your tests to matching exactly what you have in production in a service oriented infrastructure to run complex integration tests.

If you want to have a unified process and toolset to deploy or test applications across your company, you can even put those tools and scripts for deployment into a Docker container, push it into a private registry and use this container across your company’s builds. This makes a unified build environment across all your projects easy.

Some of the great things you can accomplish with our new infrastructure:

* Set up different environments for running your unit, integration or acceptance tests to keep containers small and startup times fast.
* Build specialized deployment containers to unify deployment across your company
* Use any Docker container available at the Dockerhub for your builds
* Easily switch between different versions of databases or build your own container for a special database
* Have full control over every piece of Software in the build

## Services configuration file

By default, services are expected to be in one of the following 5 files:

* `jet-services.yml`
* `jet-services.json`
* `codeship-services.yml`
* `codeship-services.json`
* `docker-compose.yml`

_Jet_ will look for a services file in this order. If you are running _Jet_ locally you can override the filename with the `--services-path` flag. Both YAML and JSON formats are accepted.

The definition of docker services is exactly the same as for Docker Compose's [docker-compose.yml definition](https://docs.docker.com/compose/yml/), with a few omissions and optional changes.

## Unavailable features

The following directives were just added to docker-compose very recently, and are expected to be implemented but have not been implemented yet:

* `extends`
* `labels`

## Linking to the host

All linking to the host is not allowed. This means the following directives are excluded:

* `external_links`
* `ports`
* `stdin_open`

## Builds

The `build` directive is extended. You can still specify a build in the same way as in Docker Compose, just using the directory. However, you can also use an extended version. You can mix formats in the services file, but not for a single service.

```yaml
app:
  build:
    image: codeship/app
    path: app
    dockerfile_path: Dockerfile
  volumes_from:
    - data
data:
  image: busybox
  volumes:
    - ./tmp/data:/data
```

* `image` specifies the output image name, as opposed to generating one by default.
* `path` allows you specify a `custom_directory` to use as the context for building the Docker container. _Note_, that the _Dockerfile_ is searched for relative to that directory. If you don't specify this option, it will default to the directory of the services file.
* `dockerfile_path` allows you to specify a file name as opposed to a directory name. This is useful for having multiple _Dockerfile_'s in the same directory.

### Using artifacts created earlier in the build

When building containers for deployment you want to make sure that you're installing exactly what is necessary for running the container in production and nothing more. Any additional tool or dependency makes the container unnecessarily big and can lead to potential issues in the future.

The best way to accomplish this is to separate the container that is building the artifact from the one running it in the future.

At first we're setting up two different services, one to compile our artifact and one to build the deployable container. In the container for compiling our artifact we're sharing the `tmp` folder in our repository checkout as `/artifacts` in the container. After building the artifact we can copy the results into `/artifacts` which will make them available in the `tmp` folder for building the deployment container. The deployment container gets built through `Dockerfile.deploy`.

```yaml
compile:
  image: compileimage:latest
  volumes:
    - ./tmp:/artifacts
deploy:
  build:
    image: deploymentcontainer
    dockerfile_path: Dockerfile.deploy
```

To create our artifact we're first running `build_artifact.sh` which is part of your repository. To trigger the building of the deploy container we're simply running `true` so the container gets built.

```yaml
- service: compile
  command: "./build_artifact.sh"
- service: deploy
  command: true
```

In `Dockerfile.deploy` we're copying the artifact that was created in the fist step in to the container. Now we have a finished container that can be deployed to production.

```Dockerfile
# Dockerfile.deploy
FROM busybox

RUN mkdir -p /app
WORKDIR /app
ADD ./tmp/artifact /app/artifact
```

We have an [example in our codeship/codeship-tool-examples](https://github.com/codeship/codeship-tool-examples/tree/master/08.deployment-container) repository as well. You can read more about how to set up host volumes in our [volumes documentation]({{ site.baseurl }}{% post_url docker/tutorials/2015-09-04-docker-volumes %}). For more insight into best practices for building containers take a look at the [Docker documentation pages](https://docs.docker.com/articles/dockerfile_best-practices/) covering it.

## Environment Variables

The standard `environment` and `env_file` directives are supported. Additionally, we support encrypted environment variables
with `encrypted_environment` and `encrypted_env_file` directives. These are the same format, except they expect encrypted variables.

See the description of the [encryption commands]({{ site.baseurl }}{% post_url docker/jet/2015-05-25-cli %}#encryption-commands) for more information and how to use this.

## Docker inside Docker

The boolean directive `add_docker` is available. If specified for a service, it will

* add the environment variables `DOCKER_HOST`, `DOCKER_TLS_VERIFY` and `DOCKER_CERT_PATH` from the host.
* if `DOCKER_CERT_PATH` is set, it will mount the certificate directory through to the container.

See [add_docker](https://github.com/codeship/codeship-tool-examples/tree/master/14.add_docker) for an example using [Docker-in-Docker](https://registry.hub.docker.com/u/jpetazzo/dind).

## Caching the Docker image

We allow the use of the previous Docker build cache during future builds. To enable this for your builds you must add the `cached` declaration to you service definition:

```yml
app:
  build:
    image: codeship/app
    dockerfile_path: Dockerfile
  cached: true
```

You must also ensure that the generated image is pushed to a repository via a push step. With this in place we will pull down a special cache tag (codeship-cache-$BRANCH) from your registry and allow the Docker build to use this image cache. During your push, we'll also update the cache tag with the updated Docker image.

This entire process should be seamless. You'll be notified of pull errors with the cache image should we be unable to pull or push due to connectivity or authentication issues, however there is no need to pre-populate an image cache.

For more information, take a look at the our [caching example](https://github.com/codeship/codeship-tool-examples/tree/master/17.caching). Be sure to check out our [Caching Tutorial]({{ site.baseurl }}{% post_url docker/tutorials/2015-09-07-caching %})  for a more detailed look at how to speed up your builds.

## Other Notes

* `link` containers will be newly created for each step.
* `volumes_from` containers will be created exactly once for all services.
